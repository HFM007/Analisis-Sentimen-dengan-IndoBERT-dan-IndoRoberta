{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d7ae3eee",
      "metadata": {
        "id": "d7ae3eee"
      },
      "source": [
        "Langkah Opsional install library pada colab jika dibutuhkan aja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-RwrOvT3pIwc",
      "metadata": {
        "id": "-RwrOvT3pIwc"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cAKERQGdgUFj",
      "metadata": {
        "id": "cAKERQGdgUFj"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall transformers peft -y\n",
        "# !pip install transformers peft"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d1cc3fc",
      "metadata": {
        "id": "1d1cc3fc"
      },
      "source": [
        "Langkah 1 Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8a6cf0",
      "metadata": {
        "id": "3c8a6cf0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import  AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, IntervalStrategy, EarlyStoppingCallback\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dfa616f",
      "metadata": {
        "id": "9dfa616f"
      },
      "source": [
        "Langkah 2 Memasukan dataset dan tahap pengolahan data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d37bb4",
      "metadata": {
        "id": "77d37bb4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"ada labelnya - Sheet1.csv\")\n",
        "df.rename(columns={'Data Komentar TIKTOK': 'text', 'Labeling': 'label'}, inplace=True)\n",
        "\n",
        "print(f\"Nilai kosong pada kolom text: {df['text'].isna().sum()}\")\n",
        "print(f\"Nilai kosong pada kolom label: {df['label'].isna().sum()}\")\n",
        "\n",
        "df = df.dropna(subset=['text'])\n",
        "df = df.dropna(subset=['label'])\n",
        "\n",
        "print(f\"DataFrame shape after dropping NA: {df.shape}\")\n",
        "\n",
        "label_map = {'netral': 0, 'positif': 1, 'negatif': 2}\n",
        "df['label'] = df['label'].map(label_map)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f303621",
      "metadata": {
        "id": "8f303621"
      },
      "source": [
        "Langkah 3 Inisialisasi model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f860a0de",
      "metadata": {
        "id": "f860a0de"
      },
      "outputs": [],
      "source": [
        "model_name = \"cahya/roberta-base-indonesian-522M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7addcc4",
      "metadata": {
        "id": "c7addcc4"
      },
      "source": [
        "Langkah 4 Tokenisasi Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8299c7d0",
      "metadata": {
        "id": "8299c7d0"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "  texts = [str(text) if text is not None else \"\" for text in examples['text']]\n",
        "  return tokenizer(texts, truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "dataset = Dataset.from_pandas(df)\n",
        "dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "sample_idx = 0\n",
        "sample_text = dataset[sample_idx]['text']\n",
        "sample_tokens = dataset[sample_idx]\n",
        "\n",
        "token_ids = sample_tokens['input_ids']\n",
        "token_words = tokenizer.convert_ids_to_tokens(token_ids[:30])\n",
        "\n",
        "token_df = pd.DataFrame({\n",
        "  'Position': range(len(token_words)),\n",
        "  'Token': token_words,\n",
        "  'ID': token_ids[:len(token_words)],\n",
        "  'Attention Mask': sample_tokens['attention_mask'][:len(token_words)]\n",
        "})\n",
        "\n",
        "token_df['Token'] = token_df['Token'].str.replace('Ä ', '', regex=False)\n",
        "\n",
        "print(f\"Text asli sebelum tokenisasi: {sample_text}\\n\")\n",
        "print(\"Hasil tokenisasi:\")\n",
        "display(token_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b4e7f46",
      "metadata": {
        "id": "9b4e7f46"
      },
      "source": [
        "Langkah 5 Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64edb3ed",
      "metadata": {
        "id": "64edb3ed"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1ff96ff",
      "metadata": {
        "id": "f1ff96ff"
      },
      "source": [
        "Langkah 6 Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c39a4fd8",
      "metadata": {
        "id": "c39a4fd8"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_map))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8875d5fe",
      "metadata": {
        "id": "8875d5fe"
      },
      "source": [
        "Langkah 7 Set training config & trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea03706",
      "metadata": {
        "id": "eea03706"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=IntervalStrategy.EPOCH,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=50,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",  # atau ganti sesuai metrik kamu\n",
        "    greater_is_better=False,\n",
        "    save_strategy=IntervalStrategy.EPOCH\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44be635e",
      "metadata": {
        "id": "44be635e"
      },
      "source": [
        "Langkah 8 Memulai training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c630a68",
      "metadata": {
        "id": "5c630a68"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e2da18",
      "metadata": {
        "id": "a7e2da18"
      },
      "source": [
        "Langkah 9 Evaluasi Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca21312",
      "metadata": {
        "id": "4ca21312"
      },
      "outputs": [],
      "source": [
        "results = trainer.evaluate()\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b12154c3",
      "metadata": {
        "id": "b12154c3"
      },
      "source": [
        "Langkah 10 Simpan hasil sentimen ke file excel baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d21ed3",
      "metadata": {
        "id": "21d21ed3"
      },
      "outputs": [],
      "source": [
        "sentiment_results = pd.DataFrame()\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(-1)\n",
        "\n",
        "sentiment_results[\"text\"] = test_dataset[\"text\"]\n",
        "sentiment_results[\"true_label\"] = test_dataset[\"label\"]\n",
        "sentiment_results[\"predicted_label\"] = predicted_labels\n",
        "\n",
        "reverse_label_map = {v: k for k, v in label_map.items()}\n",
        "sentiment_results['true_label_text'] = sentiment_results['true_label'].map(reverse_label_map)\n",
        "sentiment_results['predicted_label_text'] = sentiment_results['predicted_label'].map(reverse_label_map)\n",
        "\n",
        "y_true = np.array(test_dataset[\"label\"])\n",
        "y_pred = predicted_labels\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision_macro = precision_score(y_true, y_pred, average='macro')\n",
        "precision_weighted = precision_score(y_true, y_pred, average='weighted')\n",
        "recall_macro = recall_score(y_true, y_pred, average='macro')\n",
        "recall_weighted = recall_score(y_true, y_pred, average='weighted')\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=list(reverse_label_map.values()), output_dict=True)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (macro): {precision_macro:.4f}\")\n",
        "print(f\"Precision (weighted): {precision_weighted:.4f}\")\n",
        "print(f\"Recall (macro): {recall_macro:.4f}\")\n",
        "print(f\"Recall (weighted): {recall_weighted:.4f}\")\n",
        "print(f\"F1 Score (macro): {f1_macro:.4f}\")\n",
        "print(f\"F1 Score (weighted): {f1_weighted:.4f}\")\n",
        "\n",
        "for key, value in results.items():\n",
        "  sentiment_results[key] = value\n",
        "\n",
        "sentiment_results['accuracy'] = accuracy\n",
        "sentiment_results['precision_macro'] = precision_macro\n",
        "sentiment_results['precision_weighted'] = precision_weighted\n",
        "sentiment_results['recall_macro'] = recall_macro\n",
        "sentiment_results['recall_weighted'] = recall_weighted\n",
        "sentiment_results['f1_macro'] = f1_macro\n",
        "sentiment_results['f1_weighted'] = f1_weighted\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "with pd.ExcelWriter(\"sentiment_analysis_results.xlsx\") as writer:\n",
        "  sentiment_results.to_excel(writer, sheet_name=\"Predictions\", index=False)\n",
        "\n",
        "  metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision (macro)', 'Precision (weighted)',\n",
        "          'Recall (macro)', 'Recall (weighted)',\n",
        "          'F1 Score (macro)', 'F1 Score (weighted)'],\n",
        "    'Value': [accuracy, precision_macro, precision_weighted,\n",
        "         recall_macro, recall_weighted,\n",
        "         f1_macro, f1_weighted]\n",
        "  })\n",
        "  metrics_df.to_excel(writer, sheet_name=\"Overall Metrics\", index=False)\n",
        "\n",
        "  class_metrics = pd.DataFrame()\n",
        "  for cls in report:\n",
        "    if cls not in ['accuracy', 'macro avg', 'weighted avg']:\n",
        "      class_metrics[cls] = pd.Series(report[cls])\n",
        "  class_metrics.to_excel(writer, sheet_name=\"Class Metrics\", index=True)\n",
        "\n",
        "print(\"Sentiment analysis results saved to sentiment_analysis_results.xlsx\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}