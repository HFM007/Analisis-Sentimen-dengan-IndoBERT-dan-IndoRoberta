{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ae3eee",
   "metadata": {},
   "source": [
    "Langkah 1 Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c8a6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import  AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa616f",
   "metadata": {},
   "source": [
    "Langkah 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "77d37bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Komentar TIKTOK</th>\n",
       "      <th>Labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aku sebagai pemakai Hb noera bangga banget con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mending noera apa lauskin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tapi kok di aku ga ngaruh</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ikut gemeteran karena aku pake noera, ini cepe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeayy bangga banget sebagai pemakai hb noera</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Coba mi renk Arta lolos apa enggak makasih</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>tolong review beauty Rossa dong dok,mau beli m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Semangat Doktif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>untuk bumil boleh gak</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Data Komentar TIKTOK  Labeling\n",
       "0    Aku sebagai pemakai Hb noera bangga banget con...         1\n",
       "1                           mending noera apa lauskin?         0\n",
       "2                            tapi kok di aku ga ngaruh         2\n",
       "3    ikut gemeteran karena aku pake noera, ini cepe...         1\n",
       "4         Yeayy bangga banget sebagai pemakai hb noera         1\n",
       "..                                                 ...       ...\n",
       "994                                                NaN         0\n",
       "995         Coba mi renk Arta lolos apa enggak makasih         1\n",
       "996  tolong review beauty Rossa dong dok,mau beli m...         0\n",
       "997                                    Semangat Doktif         0\n",
       "998                              untuk bumil boleh gak         0\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ada labelnya - Sheet1.csv\")\n",
    "# Adjust the mapping to ensure 0 = netral, 1 = positif, 2 = negatif\n",
    "label_map = {'netral': 0, 'positif': 1, 'negatif': 2}\n",
    "df['Labeling'] = df['Labeling'].map(label_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f303621",
   "metadata": {},
   "source": [
    "Langkah 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f860a0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/habibfauzanmahardika/.cache/huggingface/hub/models--cahya--roberta-base-indonesian-522M/snapshots/88447f4cf0e27ca82cb25b7d841f9add236b08f3/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"cahya/roberta-base-indonesian-522M\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /Users/habibfauzanmahardika/.cache/huggingface/hub/models--cahya--roberta-base-indonesian-522M/snapshots/88447f4cf0e27ca82cb25b7d841f9add236b08f3/vocab.json\n",
      "loading file merges.txt from cache at /Users/habibfauzanmahardika/.cache/huggingface/hub/models--cahya--roberta-base-indonesian-522M/snapshots/88447f4cf0e27ca82cb25b7d841f9add236b08f3/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/habibfauzanmahardika/.cache/huggingface/hub/models--cahya--roberta-base-indonesian-522M/snapshots/88447f4cf0e27ca82cb25b7d841f9add236b08f3/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/habibfauzanmahardika/.cache/huggingface/hub/models--cahya--roberta-base-indonesian-522M/snapshots/88447f4cf0e27ca82cb25b7d841f9add236b08f3/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/habibfauzanmahardika/.cache/huggingface/hub/models--cahya--roberta-base-indonesian-522M/snapshots/88447f4cf0e27ca82cb25b7d841f9add236b08f3/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"cahya/roberta-base-indonesian-522M\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/habibfauzanmahardika/.cache/huggingface/hub/models--cahya--roberta-base-indonesian-522M/snapshots/88447f4cf0e27ca82cb25b7d841f9add236b08f3/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"cahya/roberta-base-indonesian-522M\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/habibfauzanmahardika/.cache/huggingface/hub/models--cahya--roberta-base-indonesian-522M/snapshots/88447f4cf0e27ca82cb25b7d841f9add236b08f3/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"cahya/roberta-base-indonesian-522M\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/habibfauzanmahardika/.cache/huggingface/hub/models--cahya--roberta-base-indonesian-522M/snapshots/88447f4cf0e27ca82cb25b7d841f9add236b08f3/pytorch_model.bin\n",
      "Some weights of the model checkpoint at cahya/roberta-base-indonesian-522M were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cahya/roberta-base-indonesian-522M and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"cahya/roberta-base-indonesian-522M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7addcc4",
   "metadata": {},
   "source": [
    "Langkah 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299c7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b4e7f46",
   "metadata": {},
   "source": [
    "Langkah 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edb3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1ff96ff",
   "metadata": {},
   "source": [
    "Langkah 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a4fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8875d5fe",
   "metadata": {},
   "source": [
    "Langkah 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea03706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b12154c3",
   "metadata": {},
   "source": [
    "Langkah 8 Simpan hasil sentimen ke file excel baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d21ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
